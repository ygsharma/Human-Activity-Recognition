# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Q_bxwWNOZ_Vw7SXTNVmQT4xgiie8aD-

# HumanActivityRecognition

<br>


This project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.

This dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually.

## How data was recorded

By using the sensors(Gyroscope and accelerometer) in a smartphone, they have captured '3-axial linear acceleration'(_tAcc-XYZ_) from accelerometer and '3-axial angular velocity' (_tGyro-XYZ_) from Gyroscope with several variations. 

> prefix 't' in those metrics denotes time.

> suffix 'XYZ' represents 3-axial signals in X , Y, and Z directions.

### Feature names

1. These sensor signals are preprocessed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. ie., each window has 128 readings.

# Quick overview of the dataset :

* Accelerometer and Gyroscope readings are taken from 30 volunteers(referred as subjects) while performing the following 6 Activities.

    1. Walking     
    2. WalkingUpstairs 
    3. WalkingDownstairs 
    4. Standing 
    5. Sitting 
    6. Lying.


* Readings are divided into a window of 2.56 seconds with 50% overlapping. 

* Accelerometer readings are divided into gravity acceleration and body acceleration readings,
  which has x,y and z components each.

* Gyroscope readings are the measure of angular velocities which has x,y and z components.

* Jerk signals are calculated for BodyAcceleration readings.

* Fourier Transforms are made on the above time readings to obtain frequency readings.

* Now, on all the base signal readings., mean, max, mad, sma, arcoefficient, engerybands,entropy etc., are calculated for each window.

* We get a feature vector of 561 features and these features are given in the dataset.

* Each window of readings is a datapoint of 561 features.

## Problem Framework

* 30 subjects(volunteers) data is randomly split to 70%(21) test and 30%(7) train data.
* Each datapoint corresponds one of the 6 Activities.

## Problem Statement

 + Given a new datapoint we have to predict the Activity
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# get features from the file feature.txt
features = list()
with open('/content/drive/My Drive/UCI_HAR_Dataset/features.txt') as f:
  features = [line.split()[1] for line in f.readlines()]
  
print('No of features : {}'.format(len(features)))

print(features)

"""## Obtain the  train data"""

# get the data from txt files to pandas dataframe
X_train = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/train/X_train.txt', delim_whitespace=True, header=None)
X_train.columns = features

# add subject column to dataframe 
X_train['subject'] = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/train/subject_train.txt', header=None, squeeze=True)

y_train = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/train/y_train.txt', names=['Activity'], squeeze=True)
y_train_labels = y_train.map({1: 'WALKING', 2: 'WALKING UPSTAIRS', 3: 'WALKING DOWNSTAIRS', 4: 'SITTING', 5: 'STANDING', 6:'LAYING'})

# put all column in single dataframe
train = X_train
train['Activity'] = y_train
train['ActivityName'] = y_train_labels
train.head()

train.shape

"""## Obtain the  test data"""

# get the data from txt files to pandas dataframe
X_test = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/test/X_test.txt', delim_whitespace=True, header=None)
X_test.columns = features

# add subject column to dataframe
X_test['subject'] = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/test/subject_test.txt')

y_test = pd.read_csv('/content/drive/My Drive/UCI_HAR_Dataset/test/y_test.txt', names=['Activity'], squeeze=True)
y_test_labels = y_test.map({1: 'WALKING', 2: 'WALKING UPSTAIRS', 3: 'WALKING DOWNSTAIRS', 4: 'SITTING', 5: 'STANDING', 6:'LAYING' })

# put all column in a single dataframe
test = X_test
test['Activity'] = y_test
test['ActivityName'] = y_test_labels
test.head()

test.shape

"""# Data Cleaning

## 1. Check for Duplicates
"""

# Checking for duplicates
print('No of duplicates in train : {}'.format(sum(train.duplicated())))
print('No of duplicates in test : {}'.format(sum(test.duplicated())))

"""## 2. Checking for NaN/null values"""

# Checking for null
print('No of NaN/Null values in train : {}'.format(train.isnull().values.sum()))
print('No of NaN/Null values in test : {}'.format(test.isnull().values.sum()))

"""#### Removing NaN/null values"""

# Finding the row in which NaN value is present
row_has_NaN = test.isnull().any(axis=1)
print(test[row_has_NaN])

# Dropping the row which contains NaN value
test.drop(axis=0, index=2946, inplace=True)
print('No of NaN/Null values in test : {}'.format(test.isnull().values.sum()))

"""## 3. Check for data imbalance"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('whitegrid')
plt.rcParams['font.family'] = 'Dejavu Sans'

plt.figure(figsize=(16,8))
plt.title('Data provided by each user')
sns.countplot(x='subject', hue='ActivityName', data=train)
plt.show()

plt.title('No of Datapoints per Activity')
sns.countplot(x=train.ActivityName)
plt.xticks(rotation=90)

"""## 4. Changing feature names"""

columns = train.columns

# Removing '()' from column names
columns = columns.str.replace('[()]', '')
columns = columns.str.replace('[,]', '')
columns = columns.str.replace('[-]', '')

train.columns = columns
test.columns = columns

test.columns

"""## 5. Save this dataframe in a csv files"""

# train.to_csv('/content/drive/My Drive/UCI_HAR_Dataset/new_csv_files/train1.csv', index=False)
# test.to_csv('/content/drive/My Drive/UCI_HAR_Dataset/new_csv_files/test1.csv', index=False)

"""# Exploratory Data Analysis

### 1. Featuring Engineering from Domain Knowledge

+ __Static and Dynamic Activities__

    - In static activities (sit, stand, lie down) motion information will not be very useful.
	- In the dynamic activities (Walking, WalkingUpstairs,WalkingDownstairs) motion info will be significant.

### 2. Stationary and Moving activities are completely different
"""

sns.set_palette('Set1', desat=0.80)
facetgrid = sns.FacetGrid(train, hue='ActivityName', height=6, aspect=2)
facetgrid.map(sns.distplot, 'tBodyAccMagmean', hist=False).add_legend()

plt.annotate('Stationary Activities', xy=(-0.956,17), xytext=(-0.9,23), size=20,
             va='center', ha='left',
             arrowprops=dict(arrowstyle='simple', connectionstyle='arc3,rad=0.1'))
            
plt.annotate('Moving Activities', xy=(0,3), xytext=(0.2,9), size=20,\
             va='center',ha='left',\
             arrowprops=dict(arrowstyle='simple', connectionstyle='arc3, rad=0.1'))
plt.show()

# for plotting purposes taking datapoints of each activity to a different dataframe
df1 = train[train['Activity']==1]
df2 = train[train['Activity']==2]
df3 = train[train['Activity']==3]
df4 = train[train['Activity']==4]
df5 = train[train['Activity']==5]
df6 = train[train['Activity']==6]

plt.figure(figsize=(14,7))
plt.subplot(2,2,1)
plt.title('Stationary Activities(Zoomed in)')
sns.distplot(df4['tBodyAccMagmean'],color = 'r',hist = False, label = 'Sitting')
sns.distplot(df5['tBodyAccMagmean'],color = 'm',hist = False,label = 'Standing')
sns.distplot(df6['tBodyAccMagmean'],color = 'c',hist = False, label = 'Laying')
plt.axis([-1.01, -0.5, 0, 35])
plt.legend(loc='center')

plt.subplot(2,2,2)
plt.title('Moving Activities')
sns.distplot(df1['tBodyAccMagmean'],color = 'red',hist = False, label = 'Walking')
sns.distplot(df2['tBodyAccMagmean'],color = 'blue',hist = False,label = 'Walking Up')
sns.distplot(df3['tBodyAccMagmean'],color = 'green',hist = False, label = 'Walking down')
plt.legend(loc='center right')


plt.tight_layout()
plt.show()

"""### 3. Magnitude of an acceleration can saperate it well"""

plt.figure(figsize=(7,7))
sns.boxplot(x='ActivityName', y='tBodyAccMagmean', data=train, showfliers=False, saturation=1)
plt.ylabel('Acceleration Magnitude mean')
plt.axhline(y=-0.7, xmin=0.1, xmax=0.9, dashes=(5,5), c='g')
plt.axhline(y=-0.05, xmin=0.4, dashes=(5,5), c='m')
plt.xticks(rotation=90)
plt.show()

"""__ Observations__:
- If tAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.
- If tAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.
- If tAccMean > 0.0 then the Activity is WalkingDownstairs.
- We can classify 75% the Acitivity labels with some errors.

### 4. Position of GravityAccelerationComponants also matters
"""

sns.boxplot(x='ActivityName', y='angleXgravityMean', data=train)
plt.axhline(y=0.08, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))
plt.title('Angle between X-axis and Gravity_mean', fontsize=15)
plt.xticks(rotation = 40)
plt.show()

"""__ Observations__:
* If angleX,gravityMean > 0 then Activity is Laying.
* We can classify all datapoints belonging to Laying activity with just a single if else statement.
"""

sns.boxplot(x='ActivityName', y='angleYgravityMean', data = train, showfliers=False)
plt.title('Angle between Y-axis and Gravity_mean', fontsize=15)
plt.xticks(rotation = 40)
plt.axhline(y=-0.22, xmin=0.1, xmax=0.8, dashes=(5,3), c='m')
plt.show()

"""# Apply t-sne on the data"""

import numpy as np
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns

# performs t-sne with different perplexity values and their repective plots..
#  img_name_prefix='t-sne'

def perform_tsne(X_data, y_data, perplexities, n_iter=1000):
    
    for index,perplexity in enumerate(perplexities):
      # perform t-sne 
      print('\n performing t-sne with perplexity {} and with {} iterations'.format(perplexity,n_iter))
      X_reduced = TSNE(verbose=2, perplexity=perplexity).fit_transform(X_data)
      print('Done...')

      # prepare the data for seaborn
      print('Creating plot for this t-sne visualization..')
      df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1], 'label':y_data})

      # draw the plot in appropriate place in grid
      sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,
                 palette="Set1", markers=['^','v','s','o','1','2'])
      plt.title('perplexity : {} and max iter : {}'.format(perplexity,n_iter))
      # img_name = img_name_prefix + '_prep_{}_iter{}.png'.format(perplexity, n_iter)
      plt.show()
      print('Done')

X_pre_tsne = train.drop(['subject','Activity','ActivityName'], axis=1)
y_pre_tsne = train['ActivityName']
perform_tsne(X_data=X_pre_tsne, y_data=y_pre_tsne, perplexities=[2,5,10,20,50])

